{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Analyzer: Predict & Classify Any Dataset\n",
    "\n",
    "This notebook implements a machine learning analyzer that can perform classification, regression, and clustering tasks on datasets. The implementation includes preprocessing, model training, evaluation, and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n",
    "\n",
    "First, we import all the necessary libraries for data manipulation, visualization, and machine learning. These libraries provide the foundation for our ML Analyzer application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ML Analyzer Class Definition\n",
    "\n",
    "Here we define the main ML Analyzer class that will handle all the functionality. This class initializes the necessary variables that will be used throughout the analysis process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLAnalyzer:\n",
    "    def __init__(self):\n",
    "        # Initialize variables\n",
    "        self.df = None\n",
    "        self.feature_cols = []\n",
    "        self.target_col = None\n",
    "        self.task = \"classification\"\n",
    "        self.algorithm = None\n",
    "        self.label_encoders = {}\n",
    "        self.model = None\n",
    "        self.random_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preview Functions\n",
    "\n",
    "These functions handle loading the dataset from a CSV file and displaying basic information about the data. They allow us to examine the columns and preview the first few rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def upload_csv(self, file_path):\n",
    "        try:\n",
    "            self.df = pd.read_csv(file_path)\n",
    "            print(f\"Data loaded successfully with shape: {self.df.shape}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load data: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def update_column_display(self):\n",
    "        if self.df is not None:\n",
    "            print(\"\\nColumns in dataset:\")\n",
    "            for i, col in enumerate(self.df.columns):\n",
    "                print(f\"{i}: {col}\")\n",
    "    \n",
    "    def update_data_preview(self):\n",
    "        if self.df is not None:\n",
    "            print(\"\\nData Preview:\")\n",
    "            display(self.df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Algorithm Selection Function\n",
    "\n",
    "This function updates the available algorithms based on the selected task (classification, regression, or clustering). Each task type has specific algorithms that are appropriate for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def update_algorithm_dropdown(self):\n",
    "        if self.task == \"classification\":\n",
    "            algorithms = [\"KNN\", \"SVM\", \"Decision Tree\"]\n",
    "            self.algorithm = algorithms[0]\n",
    "        elif self.task == \"regression\":\n",
    "            algorithms = [\"Linear Regression\"]\n",
    "            self.algorithm = algorithms[0]\n",
    "        else:  # clustering\n",
    "            algorithms = [\"KMeans\"]\n",
    "            self.algorithm = algorithms[0]\n",
    "        \n",
    "        print(f\"Available algorithms for {self.task}: {algorithms}\")\n",
    "        print(f\"Selected algorithm: {self.algorithm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Configuration Function\n",
    "\n",
    "This function prepares the data for modeling by validating inputs, preprocessing the data, and setting up the feature and target columns. It ensures that all necessary conditions are met before proceeding to model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def continue_to_model(self):\n",
    "        if self.df is None:\n",
    "            print(\"Error: Please upload a CSV file first.\")\n",
    "            return False\n",
    "        \n",
    "        if not self.target_col and self.task != \"clustering\":\n",
    "            print(\"Error: Please select a target column.\")\n",
    "            return False\n",
    "        \n",
    "        # Preprocess data\n",
    "        self.preprocess_data()\n",
    "        \n",
    "        # Update feature columns\n",
    "        if self.task != \"clustering\":\n",
    "            self.feature_cols = [col for col in self.df.columns if col != self.target_col]\n",
    "        else:\n",
    "            self.feature_cols = list(self.df.columns)\n",
    "        \n",
    "        print(f\"\\nFeature columns: {self.feature_cols}\")\n",
    "        if self.task != \"clustering\":\n",
    "            print(f\"Target column: {self.target_col}\")\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Preprocessing Function\n",
    "\n",
    "This function handles data preprocessing tasks such as handling missing values and encoding categorical features. Label encoding is used to convert categorical text values into numeric form that can be used by machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def preprocess_data(self):\n",
    "\n",
    "        if self.df is None:\n",
    "            return\n",
    "        \n",
    "            self.label_encoders = {}\n",
    "        \n",
    "            for col in self.df.columns:\n",
    "            if self.df[col].dtype in ['int64', 'float64']:\n",
    "                self.df[col] = self.df[col].fillna(self.df[col].mean())\n",
    "                print(f\"Filled missing values in {col} with mean\")\n",
    "            else:\n",
    "                self.df[col] = self.df[col].fillna(self.df[col].mode()[0])\n",
    "                print(f\"Filled missing values in {col} with mode\")\n",
    "        \n",
    "        # Label encode categorical columns\n",
    "        for col in self.df.columns:\n",
    "            if self.df[col].dtype == 'object':\n",
    "                le = LabelEncoder()\n",
    "                self.df[col] = le.fit_transform(self.df[col])\n",
    "                self.label_encoders[col] = le\n",
    "                print(f\"Label encoded column {col}\")\n",
    "        \n",
    "        print(\"\\nPreprocessed data:\")\n",
    "        display(self.df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Random Data Generation Function\n",
    "\n",
    "This function generates random data based on the feature columns in the dataset. It creates values within the range of each feature, which can be used for making predictions with the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def generate_random_data(self):\n",
    "        if self.df is None or not self.feature_cols:\n",
    "            print(\"Error: Please upload CSV and configure first.\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            random_data = {}\n",
    "            random_data_original = {}\n",
    "            \n",
    "            for feature in self.feature_cols:\n",
    "                if feature in self.df.columns:\n",
    "                    if pd.api.types.is_numeric_dtype(self.df[feature]):\n",
    "                        min_val = self.df[feature].min()\n",
    "                        max_val = self.df[feature].max()\n",
    "                        \n",
    "                        if pd.api.types.is_integer_dtype(self.df[feature]):\n",
    "                            value = np.random.randint(int(min_val), int(max_val) + 1)\n",
    "                        else:\n",
    "                            value = np.random.uniform(min_val, max_val)\n",
    "                        \n",
    "                        random_data[feature] = value\n",
    "                        random_data_original[feature] = value\n",
    "            \n",
    "            self.random_data = random_data\n",
    "            \n",
    "            print(\"\\nGenerated Random Data:\")\n",
    "            for feature, value in random_data.items():\n",
    "                print(f\"{feature}: {value}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating random data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Training Function\n",
    "\n",
    "This function serves as the main entry point for model training. It determines which specific training function to call based on the selected task (classification, regression, or clustering) and handles any errors that might occur during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def train_model(self):\n",
    "        if self.df is None:\n",
    "            print(\"Error: Please upload CSV first.\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            print(f\"\\nTraining {self.task} model with {self.algorithm} algorithm...\")\n",
    "            \n",
    "            if self.task == \"classification\":\n",
    "                self.train_classification_model(self.algorithm)\n",
    "            elif self.task == \"regression\":\n",
    "                self.train_regression_model()\n",
    "            else:  # clustering\n",
    "                self.train_clustering_model()\n",
    "            \n",
    "            self.generate_random_data()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error training model: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Classification Model Training Function\n",
    "\n",
    "This function handles the training of classification models (KNN, SVM, or Decision Tree). It splits the data into training and testing sets, trains the selected model, evaluates its performance using various metrics, and visualizes the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def train_classification_model(self, algorithm):\n",
    "\n",
    "        X = self.df[self.feature_cols]\n",
    "        y = self.df[self.target_col]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        print(f\"Training data shape: {X_train.shape}, Testing data shape: {X_test.shape}\")\n",
    "        \n",
    "        if algorithm == \"KNN\":\n",
    "            self.model = KNeighborsClassifier(n_neighbors=3)\n",
    "            print(\"Using KNN classifier with n_neighbors=3\")\n",
    "        elif algorithm == \"SVM\":\n",
    "            self.model = svm.SVC(kernel='rbf')\n",
    "            print(\"Using SVM classifier with rbf kernel\")\n",
    "        else:  # Decision Tree\n",
    "            self.model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "            print(\"Using Decision Tree classifier with entropy criterion and max_depth=3\")\n",
    "        \n",
    "        self.model.fit(X_train, y_train)\n",
    "        print(\"Model trained successfully\")\n",
    "        \n",
    "        y_pred = self.model.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        print(f\"\\nClassification Metrics:\")\n",
    "        print(f\"Accuracy: {accuracy:.3f}\")\n",
    "        print(f\"Precision: {precision:.3f}\")\n",
    "        print(f\"Recall: {recall:.3f}\")\n",
    "        print(f\"F1 Score: {f1:.3f}\")\n",
    "        print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.colorbar()\n",
    "        \n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\", color=\"black\")\n",
    "        \n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Regression Model Training Function\n",
    "\n",
    "This function handles the training of regression models (Linear Regression). It splits the data, trains the model, evaluates its performance using regression metrics (MAE, RMSE, R²), and visualizes the relationship between actual and predicted values with a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def train_regression_model(self):\n",
    "        X = self.df[self.feature_cols]\n",
    "        y = self.df[self.target_col]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        print(f\"Training data shape: {X_train.shape}, Testing data shape: {X_test.shape}\")\n",
    "        \n",
    "        self.model = LinearRegression()\n",
    "        self.model.fit(X_train, y_train)\n",
    "        print(\"Linear Regression model trained successfully\")\n",
    "        \n",
    "        y_pred = self.model.predict(X_test)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"\\nRegression Metrics:\")\n",
    "        print(f\"MAE: {mae:.3f}\")\n",
    "        print(f\"RMSE: {rmse:.3f}\")\n",
    "        print(f\"R² Score: {r2:.3f}\")\n",
    "        \n",
    "        df_compare = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "        print(f\"\\nActual vs Predicted (first 5 rows):\")\n",
    "        display(df_compare.head())\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "        plt.xlabel(\"Actual\")\n",
    "        plt.ylabel(\"Predicted\")\n",
    "        plt.title(\"Actual vs Predicted Scatter Plot\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Clustering Model Training Function\n",
    "\n",
    "This function handles the training of clustering models (KMeans). It identifies natural groupings in the data without requiring a target variable, visualizes the clusters using the first two numeric columns, and displays information about the cluster centers and distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def train_clustering_model(self):\n",
    "        numeric_cols = self.df.select_dtypes(include=['int64', 'float64']).columns[:2]\n",
    "        if len(numeric_cols) < 2:\n",
    "            print(\"Error: Need at least 2 numeric columns for clustering visualization\")\n",
    "            return\n",
    "        \n",
    "        X = self.df[numeric_cols]\n",
    "        print(f\"Using columns {numeric_cols[0]} and {numeric_cols[1]} for clustering visualization\")\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "        clusters = kmeans.fit_predict(X)\n",
    "        self.model = kmeans\n",
    "        print(\"KMeans model trained successfully\")\n",
    "        \n",
    "        print(f\"\\nKMeans Clustering:\")\n",
    "        print(f\"Number of clusters: 3\")\n",
    "        print(f\"Cluster centers:\\n{kmeans.cluster_centers_}\")\n",
    "        \n",
    "        unique, counts = np.unique(clusters, return_counts=True)\n",
    "        for i, (cluster, count) in enumerate(zip(unique, counts)):\n",
    "            print(f\"Cluster {cluster}: {count} samples\")\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        for i in range(3):\n",
    "            cluster_points = X[clusters == i]\n",
    "            plt.scatter(cluster_points.iloc[:, 0], cluster_points.iloc[:, 1], label=f'Cluster {i}')\n",
    "        \n",
    "        plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], \n",
    "                  s=200, marker='*', c='red', label='Centroids')\n",
    "        \n",
    "        plt.xlabel(numeric_cols[0])\n",
    "        plt.ylabel(numeric_cols[1])\n",
    "        plt.title(\"KMeans Clustering\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Prediction Function\n",
    "\n",
    "This function uses the trained model to make predictions on new data. It takes the randomly generated data and passes it through the model, then displays the prediction results in a user-friendly format based on the task type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def predict(self):\n",
    "        if not hasattr(self, 'model') or self.model is None:\n",
    "            print(\"Error: Please train a model first.\")\n",
    "            return\n",
    "        \n",
    "        if not hasattr(self, 'random_data') or self.random_data is None:\n",
    "            print(\"Error: Please generate random data first.\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            input_df = pd.DataFrame([self.random_data])\n",
    "            \n",
    "            if self.task == \"classification\":\n",
    "                prediction = self.model.predict(input_df)\n",
    "                \n",
    "                pred_value = prediction[0]\n",
    "                if pred_value == 1 or pred_value == True:\n",
    "                    result = \"Yes\"\n",
    "                else:\n",
    "                    result = \"No\"\n",
    "                \n",
    "                print(f\"\\nPrediction: {result}\")\n",
    "                \n",
    "            elif self.task == \"regression\":\n",
    "                prediction = self.model.predict(input_df)\n",
    "                print(f\"\\nPredicted value: {prediction[0]:.2f}\")\n",
    "                \n",
    "            else:  # clustering\n",
    "                cluster = self.model.predict(input_df)\n",
    "                print(f\"\\nPredicted cluster: {cluster[0]}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error making prediction: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Using the ML Analyzer\n",
    "\n",
    "Now we'll demonstrate how to use the ML Analyzer class we've defined. We'll create an instance of the analyzer and walk through the complete workflow from data loading to prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = MLAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Dataset\n",
    "\n",
    "First, we need to load a dataset from a CSV file. This step reads the data into a pandas DataFrame and displays basic information about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"your_dataset.csv\"  \n",
    "analyzer.upload_csv(file_path)\n",
    "\n",
    "analyzer.update_column_display()\n",
    "analyzer.update_data_preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configure Analysis\n",
    "\n",
    "Next, we configure the analysis by selecting the target column, task type, and algorithm. This step also preprocesses the data and prepares it for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.target_col = \"Subscribed\"  \n",
    "analyzer.task = \"classification\"  \n",
    "analyzer.update_algorithm_dropdown()\n",
    "\n",
    "analyzer.continue_to_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train Model\n",
    "\n",
    "Now we train the model using the selected algorithm. This step will split the data, train the model, evaluate its performance, and display relevant metrics and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Make Predictions\n",
    "\n",
    "Finally, we generate random data and use the trained model to make predictions. This demonstrates how the model can be used to predict outcomes for new data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analyzer.random_data is None:\n",
    "    analyzer.generate_random_data()\n",
    "\n",
    "analyzer.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
